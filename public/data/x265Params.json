{
    "libx265": {
        "-crf": {
            "valueType": "float",
            "explanation": "Quality-controlled variable bitrate. CRF is the default rate control method; it does not try to reach any particular bitrate target, instead it tries to achieve a given uniform quality and the size of the bitstream is determined by the complexity of the source video. The higher the rate factor the higher the quantization and the lower the quality. Default rate factor is 28.0. (from -1 to FLT_MAX) "
        },
        "-qp": {
            "valueType": "int",
            "explanation": "Default disabled.\nRange of values: an integer from 0 to 51\nSpecify base quantization parameter for Constant QP rate control. Using this option enables Constant QP rate control. The specified QP is assigned to P slices. I and B slices are given QPs relative to P slices using param->rc.ipFactor and param->rc.pbFactor unless QP 0 is specified, in which case QP 0 is used for all slice types. Note that QP 0 does not cause lossless encoding, it only disables quantization. "
        },
        "-forced-idr": {
            "valueType": "boolean",
            "explanation": "if forcing keyframes, force them as IDR frames (default false)"
        },
        "-preset": {
            "valueType": "string",
            "explanation": "Sets parameters to preselected values, trading off compression efficiency against encoding speed. These parameters are applied before all other input parameters are applied, and so you can override any parameters that these values control.",
            "subValues": {
                "ultrafast": {
                    "value": "0",
                    "explanation": null
                },
                "superfast": {
                    "value": "1",
                    "explanation": null
                },
                "veryfast": {
                    "value": "2",
                    "explanation": null
                },
                "faster": {
                    "value": "3",
                    "explanation": null
                },
                "fast": {
                    "value": "4",
                    "explanation": null
                },
                "medium": {
                    "value": "5",
                    "explanation": null
                },
                "slow": {
                    "value": "6",
                    "explanation": null
                },
                "slower": {
                    "value": "7",
                    "explanation": null
                },
                "veryslow": {
                    "value": "8",
                    "explanation": null
                },
                "placebo": {
                    "value": "9",
                    "explanation": null
                }
            }
        },
        "-tune": {
            "valueType": "string",
            "explanation": "Tune the settings for a particular type of source or situation. The changes will be applied after --preset but before all other parameters. \nDefault none. "
        },
        "-profile": {
            "valueType": "string",
            "explanation": "Enforce the requirements of the specified profile, ensuring the output stream will be decodable by a decoder which supports that profile. May abort the encode if the specified profile is impossible to be supported by the compile options chosen for the encoder (a high bit depth encoder will be unable to output bitstreams compliant with Main or MainStillPicture).",
            "subValues": {
                "main": {
                    "value": "0",
                    "explanation": null
                },
                "main-intra": {
                    "value": "1",
                    "explanation": null
                },
                "mainstillpicture": {
                    "value": "2",
                    "explanation": null
                },
                "main444-8": {
                    "value": "3",
                    "explanation": null
                },
                "main444-intra": {
                    "value": "4",
                    "explanation": null
                },
                "main444-stillpicture": {
                    "value": "5",
                    "explanation": null
                },
                "main10": {
                    "value": "6",
                    "explanation": null
                },
                "main10-intra": {
                    "value": "7",
                    "explanation": null
                },
                "main422-10": {
                    "value": "8",
                    "explanation": null
                },
                "main422-10-intra": {
                    "value": "9",
                    "explanation": null
                },
                "main444-10": {
                    "value": "10",
                    "explanation": null
                },
                "main444-10-intra": {
                    "value": "11",
                    "explanation": null
                },
                "main12": {
                    "value": "12",
                    "explanation": null
                },
                "main12-intra": {
                    "value": "13",
                    "explanation": null
                },
                "main422-12": {
                    "value": "14",
                    "explanation": null
                },
                "main422-12-intra": {
                    "value": "15",
                    "explanation": null
                },
                "main444-12": {
                    "value": "16",
                    "explanation": null
                },
                "main444-12-intra": {
                    "value": "17",
                    "explanation": null
                }
            }
        },
        "-x265-params": {
            "valueType": "dictionary",
            "explanation": "set the x265 configuration using a :-separated list of key=value parameters",
            "subValues": {
                "ssim":{
                    "valueType":"boolean",
                    "explanation":"Calculate and report Structural Similarity values. It is recommended to use --tune ssim if you are measuring ssim, else the results should not be used for comparison purposes. \nDefault disabled"
                },
                "psnr":{
                    "valueType":"boolean",
                    "explanation":"Calculate and report Peak Signal to Noise Ratio. It is recommended to use --tune psnr if you are measuring PSNR, else the results should not be used for comparison purposes. \nDefault disabled"
                },
                "asm":{
                    "valueType":"string",
                    "explanation":"x265 will use all detected CPU SIMD architectures by default. You can disable all assembly by using --no-asm or you can specify a comma separated list of SIMD architectures to use, matching these strings: MMX2, SSE, SSE2, SSE3, SSSE3, SSE4, SSE4.1, SSE4.2, AVX, XOP, FMA4, AVX2, FMA3\n Some higher architectures imply lower ones being present, this is handled implicitly.\nOne may also directly supply the CPU capability bitmap as an integer.\nNote that by specifying this option you are overriding x265’s CPU detection and it is possible to do this wrong. You can cause encoder crashes by specifying SIMD architectures which are not supported on your CPU.\nDefault: auto-detected SIMD architectures"
                },
                "frame-threads":{
                    "valueType":"int",
                    "explanation":"Number of concurrently encoded frames. Using a single frame thread gives a slight improvement in compression, since the entire reference frames are always available for motion compensation, but it has severe performance implications. Default is an autodetected count based on the number of CPU cores and whether WPP is enabled or not.\nOver-allocation of frame threads will not improve performance, it will generally just increase memory use.\nValues: any value between 0 and 16. Default is 0, auto-detect"
                },
                "wpp":{
                    "valueType":"boolean",
                    "explanation":"Enable Wavefront Parallel Processing. The encoder may begin encoding a row as soon as the row above it is at least two CTUs ahead in the encode process. This gives a 3-5x gain in parallelism for about 1% overhead in compression efficiency.\nThis feature is implicitly disabled when no thread pool is present.\nDefault: Enabled"
                },
                "pmode":{
                    "valueType":"boolean",
                    "explanation":"Parallel mode decision, or distributed mode analysis. When enabled the encoder will distribute the analysis work of each CU (merge, inter, intra) across multiple worker threads. Only recommended if x265 is not already saturating the CPU cores. In RD levels 3 and 4 it will be most effective if –rect is enabled. At RD levels 5 and 6 there is generally always enough work to distribute to warrant the overhead, assuming your CPUs are not already saturated.\n–pmode will increase utilization without reducing compression efficiency. In fact, since the modes are all measured in parallel it makes certain early-outs impractical and thus you usually get slightly better compression when it is enabled (at the expense of not skipping improbable modes). This bypassing of early-outs can cause pmode to slow down encodes, especially at faster presets.\nThis feature is implicitly disabled when no thread pool is present.\nDefault disabled"
                },
                "pme":{
                    "valueType":"boolean",
                    "explanation":"Parallel motion estimation. When enabled the encoder will distribute motion estimation across multiple worker threads when more than two references require motion searches for a given CU. Only recommended if x265 is not already saturating CPU cores. --pmode is much more effective than this option, since the amount of work it distributes is substantially higher. With –pme it is not unusual for the overhead of distributing the work to outweigh the parallelism benefits.\nThis feature is implicitly disabled when no thread pool is present.\n –pme will increase utilization on many core systems with no effect on the output bitstream.\nDefault disabled"
                },
                "slices":{
                    "valueType":"int",
                    "explanation":"Encode each incoming frame as multiple parallel slices that may be decoded independently. Support available only for rectangular slices that cover the entire width of the image.\n Recommended for improving encoder performance only if frame-parallelism and WPP are unable to maximize utilization on given hardware.\nDefault: 1 slice per frame. Experimental feature"
                },
                "copy-pic":{
                    "valueType":"boolean",
                    "explanation":"Allow encoder to copy input x265 pictures to internal frame buffers. When disabled, x265 will not make an internal copy of the input picture and will work with the application’s buffers. While this allows for deeper integration, it is the responsibility of the application to (a) ensure that the allocated picture has extra space for padding that will be done by the library, and (b) the buffers aren’t recycled until the library has completed encoding this frame (which can be figured out by tracking NALs output by x265)\nDefault: enabled"
                },
                "level-idc":{
                    "valueType":"float",
                    "explanation":"Minimum decoder requirement level. Defaults to 0, which implies auto-detection by the encoder. If specified, the encoder will attempt to bring the encode specifications within that specified level. If the encoder is unable to reach the level it issues a warning and aborts the encode. The requested level will be signaled in the bitstream even if it is higher than the actual level.\nBeware, specifying a decoder level will force the encoder to enable VBV for constant rate factor encodes, which may introduce non-determinism.\nThe value is specified as a float or as an integer with the level times 10, for example level 5.1 is specified as “5.1” or “51”, and level 5.0 is specified as “5.0” or “50”.\nAnnex A levels: 1, 2, 2.1, 3, 3.1, 4, 4.1, 5, 5.1, 5.2, 6, 6.1, 6.2, 8.5"
                },
                "high-tier":{
                    "valueType":"boolean",
                    "explanation":"If --level-idc has been specified, –high-tier allows the support of high tier at that level. The encoder will first attempt to encode at the specified level, main tier first, turning on high tier only if necessary and available at that level. If your requested level does not support a High tier, high tier will not be supported. If –no-high-tier has been specified, then the encoder will attempt to encode only at the main tier.\n Default: enabled"
                },
                "ref":{
                    "valueType":"int",
                    "explanation":"Max number of L0 references to be allowed. This number has a linear multiplier effect on the amount of work performed in motion search but will generally have a beneficial effect on compression and distortion.\n Note that x265 allows up to 16 L0 references but the HEVC specification only allows a maximum of 8 total reference frames. So if you have B frames enabled only 7 L0 refs are valid and if you have --b-pyramid enabled (which is enabled by default in all presets), then only 6 L0 refs are the maximum allowed by the HEVC specification. If x265 detects that the total reference count is greater than 8, it will issue a warning that the resulting stream is non-compliant and it signals the stream as profile NONE and level NONE and will abort the encode unless --allow-non-conformance it specified. Compliant HEVC decoders may refuse to decode such streams.\nDefault 3"
                },
                "allow-non-conformance":{
                    "valueType":"boolean",
                    "explanation":"Allow libx265 to generate a bitstream with profile and level NONE. By default, it will abort any encode which does not meet strict level compliance. The two most likely causes for non-conformance are --ctu being too small, --ref being too high, or the bitrate or resolution being out of specification.\nDefault: disabled"
                },
                "uhd-bd":{
                    "valueType":"boolean",
                    "explanation":"Enable Ultra HD Blu-ray format support. If specified with incompatible encoding options, the encoder will attempt to modify/set the right encode specifications. If the encoder is unable to do so, this option will be turned OFF. Highly experimental.\nDefault: disabled"
                },
                "rd":{
                    "valueType":"int",
                    "explanation":"Level of RDO in mode decision. The higher the value, the more exhaustive the analysis and the more rate distortion optimization is used. The lower the value the faster the encode, the higher the value the smaller the bitstream (in general). Default 3\nNote that this table aims for accuracy but is not necessarily our final target behavior for each mode.\nRange of values: 1: least .. 6: full RDO analysis\nOptions which affect the coding unit quad-tree, sometimes referred to as the prediction quad-tree."
                },
                "ctu":{
                    "valueType":"int",
                    "explanation":"Maximum CU size (width and height). The larger the maximum CU size, the more efficiently x265 can encode flat areas of the picture, giving large reductions in bitrate. However, this comes at a loss of parallelism with fewer rows of CUs that can be encoded in parallel, and less frame parallelism as well. Because of this the faster presets use a CU size of 32. \nDefault: 64. Value can be chosen from 16, 32, 64."
                },
                "min-cu-size":{
                    "valueType":"int",
                    "explanation":"Minimum CU size (width and height). By using 16 or 32 the encoder will not analyze the cost of CUs below that minimum threshold, saving considerable amounts of compute with a predictable increase in bitrate. This setting has a large effect on performance on the faster presets.\nDefault: 8 (minimum 8x8 CU for HEVC, best compression efficiency). Value can be chosen from 8, 16, 32."
                },
                "limit-refs":{
                    "valueType":"int",
                    "explanation":"When set to X265_REF_LIMIT_DEPTH (1) x265 will limit the references analyzed at the current depth based on the references used to code the 4 sub-blocks at the next depth. For example, a 16x16 CU will only use the references used to code its four 8x8 CUs.\nWhen set to X265_REF_LIMIT_CU (2), the rectangular and asymmetrical partitions will only use references selected by the 2Nx2N motion search (including at the lowest depth which is otherwise unaffected by the depth limit).\nWhen set to 3 (X265_REF_LIMIT_DEPTH && X265_REF_LIMIT_CU), the 2Nx2N motion search at each depth will only use references from the split CUs and the rect/amp motion searches at that depth will only use the reference(s) selected by 2Nx2N.\nFor all non-zero values of limit-refs, the current depth will evaluate intra mode (in inter slices), only if intra mode was chosen as the best mode for at least one of the 4 sub-blocks.\nYou can often increase the number of references you are using (within your decoder level limits) if you enable one or both of these flags. \nValue can be chosen from 0, 1, 2 and 3."
                },
                "limit-modes":{
                    "valueType":"int",
                    "explanation":"When enabled, limit-modes will limit modes analyzed for each CU using cost metrics from the 4 sub-CUs. When multiple inter modes like --rect and/or --amp are enabled, this feature will use motion cost heuristics from the 4 sub-CUs to bypass modes that are unlikely to be the best choice. This can significantly improve performance when rect and/or --amp are enabled at minimal compression efficiency loss."
                },
                "rect":{
                    "valueType":"boolean",
                    "explanation":"Enable analysis of rectangular motion partitions Nx2N and 2NxN (50/50 splits, two directions). Default disabled"
                },
                "amp":{
                    "valueType":"boolean",
                    "explanation":"Enable analysis of asymmetric motion partitions (75/25 splits, four directions). At RD levels 0 through 4, AMP partitions are only considered at CU sizes 32x32 and below. At RD levels 5 and 6, it will only consider AMP partitions as merge candidates (no motion search) at 64x64, and as merge or inter candidates below 64x64.\nThe AMP partitions which are searched are derived from the current best inter partition. If Nx2N (vertical rectangular) is the best current prediction, then left and right asymmetrical splits will be evaluated. If 2NxN (horizontal rectangular) is the best current prediction, then top and bottom asymmetrical splits will be evaluated, If 2Nx2N is the best prediction, and the block is not a merge/skip, then all four AMP partitions are evaluated.\nThis setting has no effect if rectangular partitions are disabled. Default disabled"
                },
                "early-skip":{
                    "valueType":"boolean",
                    "explanation":"Measure 2Nx2N merge candidates first; if no residual is found, additional modes at that depth are not analysed. Default disabled"
                },
                "rskip":{
                    "valueType":"int",
                    "explanation":"This option determines early exit from CU depth recursion in modes 1 and 2. When a skip CU is found, additional heuristics (depending on the RD level and rskip mode) are used to decide whether to terminate recursion. The following table summarizes the behavior.",
                    "subValues":{
                        "0":{"value": "0",
                            "explanation": null
                        },
                        "1":{"value": "1",
                            "explanation": null
                        },
                        "2":{"value": "2",
                            "explanation": null
                        }
                    }
                },
                "rskip-edge-threshold":{
                    "valueType":"int",
                    "explanation":"Range of the value: 0-100.\nDenotes the minimum expected edge-density percentage within the CU, below which the recursion is skipped. Internally normalized to decimal value in x265 library. Recommended low thresholds for slow encodes and high for fast encodes. Default: 5, requires --rskip mode 2 to be enabled."
                },
                "splitrd-skip":{
                    "valueType":"boolean",
                    "explanation":"Enable skipping split RD analysis when sum of split CU rdCost larger than one split CU rdCost for Intra CU. Default disabled."
                },
                "fast-intra":{
                    "valueType":"boolean",
                    "explanation":"Perform an initial scan of every fifth intra angular mode, then check modes +/- 2 distance from the best mode, then +/- 1 distance from the best mode, effectively performing a gradient descent. When enabled 10 modes in total are checked. When disabled all 33 angular modes are checked. Only applicable for --rd levels 4 and below (medium preset and faster)."
                },
                "b-intra":{
                    "valueType":"boolean",
                    "explanation":"Enables the evaluation of intra modes in B slices. \nDefault disabled."
                },
                "cu-lossless":{
                    "valueType":"boolean",
                    "explanation":"For each CU, evaluate lossless (transform and quant bypass) encode of the best non-lossless mode option as a potential rate distortion optimization. If the global option --lossless has been specified, all CUs will be encoded as lossless unconditionally regardless of whether this option was enabled. Default disabled.\nOnly effective at RD levels 3 and above, which perform RDO mode decisions."
                },
                "tskip-fast":{
                    "valueType":"boolean",
                    "explanation":"Only evaluate transform skip for NxN intra predictions (4x4 blocks). Only applicable if transform skip is enabled. For chroma, only evaluate if luma used tskip. Inter block tskip analysis is unmodified. \nDefault disabled"
                },
                "rd-refine":{
                    "valueType":"boolean",
                    "explanation":"For each analysed CU, calculate R-D cost on the best partition mode for a range of QP values, to find the optimal rounding effect. \nDefault disabled. Only effective at RD levels 5 and 6"
                },
                "analysis-save":{
                    "valueType":"string",
                    "explanation":"Encoder outputs analysis information of each frame. Analysis data from save mode is written to the file specified. Requires cutree, pmode to be off. \nDefault disabled.The amount of analysis data stored is determined by --analysis-save-reuse-level."
                },
                "analysis-load":{
                    "valueType":"string",
                    "explanation":"Encoder reuses analysis information from the file specified. By reading the analysis data written by an earlier encode of the same sequence, substantial redundant work may be avoided. Requires cutree, pmode to be off. \nDefault disabled.\nThe amount of analysis data reused is determined by --analysis-load-reuse-level."
                },
                "analysis-reuse-file":{
                    "valueType":"string",
                    "explanation":"Specify a filename for --multi-pass-opt-analysis and option:–multi-pass-opt-distortion. If no filename is specified, x265_analysis.dat is used."
                },
                "analysis-save-reuse-level":{
                    "valueType":"int",
                    "explanation":"The range of the value is from 0 to 10. ‘analysis-save-reuse-level’ denotes the amount of information stored during --analysis-save and ‘analysis-load-reuse-level’ denotes the amount of information reused during --analysis-load. Higher the value, higher the information stored/reused, faster the encode. Default 0. If not set during analysis-save/load, the encoder will internally configure them to 5.\nNote that --analysis-save-reuse-level and --analysis-load-reuse-level must be paired with --analysis-save and --analysis-load respectively."
                },
                "analysis-load-reuse-level":{
                    "valueType":"int",
                    "explanation":"The range of the value is from 0 to 10. ‘analysis-save-reuse-level’ denotes the amount of information stored during --analysis-save and ‘analysis-load-reuse-level’ denotes the amount of information reused during --analysis-load. Higher the value, higher the information stored/reused, faster the encode. Default 0. If not set during analysis-save/load, the encoder will internally configure them to 5.\nNote that --analysis-save-reuse-level and --analysis-load-reuse-level must be paired with --analysis-save and --analysis-load respectively."
                },
                "refine-mv-type":{
                    "valueType":"string",
                    "explanation":"Reuse MV information received through API call. Currently receives information for AVC size and the accepted string input is “avc”. Default is disabled."
                },
                "refine-ctu-distortion":{
                    "valueType":"int",
                    "explanation":"Store/normalize ctu distortion in analysis-save/load. 0 - Disabled. 1 - Save ctu distortion to the analysis file specified during --analysis-save.\nLoad CTU distortion from the analysis file and normalize it across every frame during --analysis-load.\nDefault 0."
                },
                "scale-factor":{
                    "valueType":"int",
                    "explanation":"Factor by which input video is scaled down for analysis save mode. This option should be coupled with --analysis-load/--analysis-save at reuse levels 1 to 6 and 10. The ctu size of load can either be the same as that of save or double the size of save. \nDefault 0."
                },
                "refine-intra":{
                    "valueType":"int",
                    "explanation":"Enables refinement of intra blocks in current encode. Default 0.\nLevel 0 - Forces both mode and depth from the save encode.\nLevel 1 - Evaluates all intra modes at current depth(n) and at depth (n+1) when current block size is one greater than the min-cu-size. Forces modes for larger blocks.\nLevel 2 - In addition to the functionality of level 1, at all depths, force (a) only depth when angular mode is chosen by the save encode. (b) depth and mode when other intra modes are chosen by the save encode.\nLevel 3 - Perform analysis of intra modes for depth reused from first encode.\nLevel 4 - Does not reuse any analysis information - redo analysis for the intra block.",
                    "subValues":{
                        "0":{
                            "value":"0",
                            "explanation":"Level 0 - Forces both mode and depth from the save encode."
                        },
                        "1":{
                            "value":"1",
                            "explanation":"Level 1 - Evaluates all inter modes at current depth(n) and at depth (n+1) when current block "
                        },
                        "2":{
                            "value":"2",
                            "explanation":"Level 2 - In addition to the functionality of level 1, restricts the modes evaluated when specific modes are decided as the best mode by the save encode."
                        },
                        "3":{
                            "value":"3",
                            "explanation":"Level 3 - Perform analysis of inter modes while reusing depths from the save encode."
                        }
                    }
                },
                "refine-mv":{
                    "valueType":"int",
                    "explanation":"Enables refinement of motion vector for scaled video. Evaluates the best motion vector based on the level selected. Default 1.\nLevel 1 - Search around scaled MV.\nLevel 2 - Level 1 + Search around best AMVP cand.\nLevel 3 - Level 2 + Search around the other AMVP cand.",
                    "subValues":{
                        "1":{
                            "value":"1",
                            "explanation":"Level 1 - Search around scaled MV."
                        },
                        "2":{
                            "value":"2",
                            "explanation":"Level 2 - Level 1 + Search around best AMVP cand."
                        },
                        "3":{
                            "value":"3",
                            "explanation":"Level 3 - Level 2 + Search around the other AMVP cand."
                        }
                    }
                },
                "dynamic-refine":{
                    "valueType":"boolean",
                    "explanation":"Dynamically switches --refine-inter levels 0-3 based on the content and the encoder settings. It is recommended to use --refine-intra 4 with dynamic refinement.\nDefault disabled."
                },
                "rdoq-level":{
                    "valueType":"int",
                    "explanation":"Specify the amount of rate-distortion analysis to use within quantization:\nAt level 0 rate-distortion cost is not considered in quant\nAt level 1 rate-distortion cost is used to find optimal rounding values for each level (and allows psy-rdoq to be effective). It trades-off the signaling cost of the coefficient vs its post-inverse quant distortion from the pre-quant coefficient. When --psy-rdoq is enabled, this formula is biased in favor of more energy in the residual (larger coefficient absolute levels)\nAt level 2 rate-distortion cost is used to make decimate decisions on each 4x4 coding group, including the cost of signaling the group within the group bitmap. If the total distortion of not signaling the entire coding group is less than the rate cost, the block is decimated. Next, it applies rate-distortion cost analysis to the last non-zero coefficient, which can result in many (or all) of the coding groups being decimated. Psy-rdoq is less effective at preserving energy when RDOQ is at level 2, since it only has influence over the level distortion costs.",
                    "subValues":{
                        "0":{
                            "value":"0",
                            "explanation":"At level 0 rate-distortion cost is not considered in quant."
                        },
                        "1":{
                            "value":"1",
                            "explanation":"At level 1 rate-distortion cost is used to find optimal rounding values for each level (and allows psy-rdoq to be effective). It trades-off the signaling cost of the coefficient vs its post-inverse quant distortion from the pre-quant coefficient. When --psy-rdoq is enabled, this formula is biased in favor of more energy in the residual (larger coefficient absolute levels)."
                        },
                        "2":{
                            "value":"2",
                            "explanation":"At level 2 rate-distortion cost is used to make decimate decisions on each 4x4 coding group, including the cost of signaling the group within the group bitmap. If the total distortion of not signaling the entire coding group is less than the rate cost, the block is decimated. Next, it applies rate-distortion cost analysis to the last non-zero coefficient, which can result in many (or all) of the coding groups being decimated. Psy-rdoq is less effective at preserving energy when RDOQ is at level 2, since it only has influence over the level distortion costs."
                        }
                    }
                },
                "no-rdoq-level":{
                    "valueType":"boolean",
                    "explanation":"No rdoq-level."
                },
                "tu-intra-depth":{
                    "valueType":"int",
                    "explanation":"The range of the value is from 1 to 4.\nThe transform unit (residual) quad-tree begins with the same depth as the coding unit quad-tree, but the encoder may decide to further split the transform unit tree if it improves compression efficiency. This setting limits the number of extra recursion depth which can be attempted for intra coded units. Default: 1, which means the residual quad-tree is always at the same depth as the coded unit quad-tree\nNote that when the CU intra prediction is NxN (only possible with 8x8 CUs), a TU split is implied, and thus the residual quad-tree begins at 4x4 and cannot split any further."
                },
                "tu-inter-depth":{
                    "valueType":"int",
                    "explanation":"The range of the value is from 1 to 4.\nThe transform unit (residual) quad-tree begins with the same depth as the coding unit quad-tree, but the encoder may decide to further split the transform unit tree if it improves compression efficiency. This setting limits the number of extra recursion depth which can be attempted for inter coded units. Default: 1. which means the residual quad-tree is always at the same depth as the coded unit quad-tree unless the CU was coded with rectangular or AMP partitions, in which case a TU split is implied and thus the residual quad-tree begins one layer below the CU quad-tree."
                },
                "limit-tu":{
                    "valueType":"int",
                    "explanation":"Default: 0\nEnables early exit from TU depth recursion, for inter coded blocks.\nLevel 1 - decides to recurse to next higher depth based on cost comparison of full-size TU and split TU.\nLevel 2 - based on first split subTU’s depth, limits recursion of other split subTUs.\nLevel 3 - based on the average depth of the co-located and the neighbor CUs’ TU depth, limits recursion of the current CU.\nLevel 4 - uses the depth of the neighboring/ co-located CUs TU depth to limit the 1st subTU depth. The 1st subTU depth is taken as the limiting depth for the other subTUs.\nEnabling levels 3 or 4 may cause a mismatch in the output bitstreams between --analysis-save and --analysis-load as all neighboring CUs TU depth may not be available in the --analysis-load run as only the best mode’s information is available to it.",
                    "subValues":{
                        "0":{
                            "value":"0",
                            "explanation":"Off"
                        },
                        "1":{
                            "value":"1",
                            "explanation":"Level 1 - decides to recurse to next higher depth based on cost comparison of full-size TU and split TU."
                        },
                        "2":{
                            "value":"2",
                            "explanation":"Level 2 - based on first split subTU’s depth, limits recursion of other split subTUs."
                        },
                        "3":{
                            "value":"3",
                            "explanation":"Level 3 - based on the average depth of the co-located and the neighbor CUs’ TU depth, limits recursion of the current CU."
                        },
                        "4":{
                            "value":"4",
                            "explanation":"Level 4 - uses the depth of the neighboring/ co-located CUs TU depth to limit the 1st subTU depth. The 1st subTU depth is taken as the limiting depth for the other subTUs."
                        }
                    }
                },
                "nr-intra":{
                    "valueType":"int",
                    "explanation":"Noise reduction - an adaptive deadzone applied after DCT (subtracting from DCT coefficients), before quantization. It does no pixel-level filtering, doesn’t cross DCT block boundaries, has no overlap, The higher the strength value parameter, the more aggressively it will reduce noise.\nEnabling noise reduction will make outputs diverge between different numbers of frame threads. Outputs will be deterministic but the outputs of -F2 will no longer match the outputs of -F3, etc."
                },
                "nr-inter":{
                    "valueType":"int",
                    "explanation":"Noise reduction - an adaptive deadzone applied after DCT (subtracting from DCT coefficients), before quantization. It does no pixel-level filtering, doesn’t cross DCT block boundaries, has no overlap, The higher the strength value parameter, the more aggressively it will reduce noise.\nEnabling noise reduction will make outputs diverge between different numbers of frame threads. Outputs will be deterministic but the outputs of -F2 will no longer match the outputs of -F3, etc."
                },
                "tskip":{
                    "valueType":"boolean",
                    "explanation":"Enable evaluation of transform skip (bypass DCT but still use quantization) coding for 4x4 TU coded blocks.\nOnly effective at RD levels 3 and above, which perform RDO mode decisions. \nDefault disabled"
                },
                "rdpenalty":{
                    "valueType":"int",
                    "explanation":"Default 0, disabled.\nWhen set to 1, transform units of size 32x32 are given a 4x bit cost penalty compared to smaller transform units, in intra coded CUs in P or B slices.\nWhen set to 2, transform units of size 32x32 are not even attempted, unless otherwise required by the maximum recursion depth. For this option to be effective with 32x32 intra CUs, --tu-intra-depth must be at least 2. For it to be effective with 64x64 intra CUs, --tu-intra-depth must be at least 3.\nNote that in HEVC an intra transform unit (a block of the residual quad-tree) is also a prediction unit, meaning that the intra prediction signal is generated for each TU block, the residual subtracted and then coded. The coding unit simply provides the prediction modes that will be used when predicting all of the transform units within the CU. This means that when you prevent 32x32 intra transform units, you are preventing 32x32 intra predictions.",
                    "subValues":{
                        "0":{
                            "value":"0",
                            "explanation":"Disabled."
                        },
                        "1":{
                            "value":"1",
                            "explanation":"4x cost penalty."
                        },
                        "2":{
                            "value":"2",
                            "explanation":"Force splits."
                        }
                    }
                },
                "max-tu-size":{
                    "valueType":"int",
                    "explanation":"Maximum TU size (width and height). The residual can be more efficiently compressed by the DCT transform when the max TU size is larger, but at the expense of more computation. Transform unit quad-tree begins at the same depth of the coded tree unit, but if the maximum TU size is smaller than the CU size then transform QT begins at the depth of the max-tu-size. \nDefault: 32.",
                    "subValues":{
                        "32":{
                            "value":"32",
                            "explanation":null
                        },
                        "16":{
                            "value":"16",
                            "explanation":null
                        },
                        "8":{
                            "value":"8",
                            "explanation":null
                        },
                        "4":{
                            "value":"4",
                            "explanation":null
                        }
                    }
                },
                "dynamic-rd":{
                    "valueType":"int",
                    "explanation":"Increases the RD level at points where quality drops due to VBV rate control enforcement. The number of CUs for which the RD is reconfigured is determined based on the strength. Strength 1 gives the best FPS, strength 4 gives the best SSIM. Strength 0 switches this feature off. Default: 0.\nEffective for RD levels 4 and below.",
                    "subValues":{
                        "0":{
                            "value":"0",
                            "explanation":null
                        },
                        "1":{
                            "value":"1",
                            "explanation":null
                        },
                        "2":{
                            "value":"2",
                            "explanation":null
                        },
                        "3":{
                            "value":"3",
                            "explanation":null
                        },
                        "4":{
                            "value":"4",
                            "explanation":null
                        }
                    }
                },
                "ssim-rd":{
                    "valueType":"boolean",
                    "explanation":"Enable/Disable SSIM RDO. SSIM is a better perceptual quality assessment method as compared to MSE. SSIM based RDO calculation is based on residual divisive normalization scheme. This normalization is consistent with the luminance and contrast masking effect of Human Visual System. It is used for mode selection during analysis of CTUs and can achieve significant gain in terms of objective quality metrics SSIM and PSNR. It only has effect on presets which use RDO-based mode decisions (--rd 3 and above)."
                },
                "max-merge":{
                    "valueType":"int",
                    "explanation":"The range of the value is from 1 to 5. \nMaximum number of neighbor (spatial and temporal) candidate blocks that the encoder may consider for merging motion predictions. If a merge candidate results in no residual, it is immediately selected as a “skip”. Otherwise the merge candidates are tested as part of motion estimation when searching for the least cost inter option. The max candidate number is encoded in the SPS and determines the bit cost of signaling merge CUs. \nDefault 2"
                },
                "me":{
                    "valueType":"int",
                    "explanation":"Motion search method. Generally, the higher the number the harder the ME method will try to find an optimal match. Diamond search is the simplest. Hexagon search is a little better. Uneven Multi-Hexagon is an adaption of the search method used by x264 for slower presets. Star is a three-step search adapted from the HM encoder: a star-pattern search followed by an optional radix scan followed by an optional star-search refinement. Full is an exhaustive search; an order of magnitude slower than all other searches but not much better than umh or star. SEA is similar to x264’s ESA implementation and a speed optimization of full search.\nIt is a three-step motion search where the DC calculation is followed by ADS calculation followed by SAD of the passed motion vector candidates.",
                    "subValues":{
                        "dia":{
                            "value":"0",
                            "explanation":null
                        },
                        "hex":{
                            "value":"1",
                            "explanation":null
                        },
                        "umh":{
                            "value":"2",
                            "explanation":null
                        },
                        "star":{
                            "value":"3",
                            "explanation":null
                        },
                        "sea":{
                            "value":"4",
                            "explanation":null
                        },
                        "full":{
                            "value":"5",
                            "explanation":null
                        }
                    }
                },
                "subme":{
                    "valueType":"int",
                    "explanation":"The reange of this value is from 0 to 7. \nAmount of subpel refinement to perform. The higher the number the more subpel iterations and steps are performed. \nDefault 2.\nAt –subme values larger than 2, chroma residual cost is included in all subpel refinement steps and chroma residual is included in all motion estimation decisions (selecting the best reference picture in each list, and choosing between merge, uni-directional motion and bi-directional motion). The ‘slow’ preset is the first preset to enable the use of chroma residual."
                },
                "merange":{
                    "valueType":"int",
                    "explanation":"Motion search range. Default 57\nRange of values: an integer from 0 to 32768.\nThe default is derived from the default CTU size (64) minus the luma interpolation half-length (4) minus maximum subpel distance (2) minus one extra pixel just in case the hex search method is used. If the search range were any larger than this, another CTU row of latency would be required for reference frames."
                },
                "temporal-mvp":{
                    "valueType":"boolean",
                    "explanation":"Enable temporal motion vector predictors in P and B slices. This enables the use of the motion vector from the collocated block in the previous frame to be used as a predictor. Default is enabled."
                },
                "weightp":{
                    "valueType":"boolean",
                    "explanation":"Enable weighted prediction in P slices. This enables weighting analysis in the lookahead, which influences slice decisions, and enables weighting analysis in the main encoder which allows P reference samples to have a weight function applied to them prior to using them for motion compensation. In video which has lighting changes, it can give a large improvement in compression efficiency. \nDefault is enabled"
                },
                "weightb":{
                    "valueType":"boolean",
                    "explanation":"Enable weighted prediction in B slices. \nDefault disabled"
                },
                "analyze-src-pics":{
                    "valueType":"boolean",
                    "explanation":"Enable motion estimation with source frame pixels, in this mode, motion estimation can be computed independently. \nDefault disabled."
                },
                "hme":{
                    "valueType":"boolean",
                    "explanation":"Enable 3-level Hierarchical motion estimation at One-Sixteenth, Quarter and Full resolution. \nDefault disabled."
                },
                "hme-search":{
                    "valueType":"string",
                    "explanation":"Motion search method for HME Level 0, 1 and 2. Refer to --me for values. Specify search method for each level. Alternatively, specify a single value which will apply to all levels. \nDefault is hex,umh,umh for levels 0,1,2 respectively."
                },
                "hme-range":{
                    "valueType":"string",
                    "explanation":"Search range for HME level 0, 1 and 2. The Search Range for each HME level must be between 0 and 32768(excluding). Default search range is 16,32,48 for level 0,1,2 respectively."
                },
                "strong-intra-smoothing":{
                    "valueType":"boolean",
                    "explanation":"Enable strong intra smoothing for 32x32 intra blocks. This flag performs bi-linear interpolation of the corner reference samples for a strong smoothing effect. The purpose is to prevent blocking or banding artifacts in regions with few/zero AC coefficients. \nDefault enabled"
                },
                "constrained-intra":{
                    "valueType":"boolean",
                    "explanation":"Constrained intra prediction. When generating intra predictions for blocks in inter slices, only intra-coded reference pixels are used. Inter-coded reference pixels are replaced with intra-coded neighbor pixels or default values. The general idea is to block the propagation of reference errors that may have resulted from lossy signals. \nDefault disabled"
                },
                "psy-rd":{
                    "valueType":"float",
                    "explanation":"Range of values: 0 .. 5.0. Default 2.0\nInfluence rate distortion optimized mode decision to preserve the energy of the source image in the encoded image at the expense of compression efficiency. It only has effect on presets which use RDO-based mode decisions (--rd 3 and above). 1.0 is a typical value."
                },
                "psy-rdoq":{
                    "valueType":"float",
                    "explanation":"Range of values: 0 .. 50.0\nInfluence rate distortion optimized quantization by favoring higher energy in the reconstructed image. This generally improves perceived visual quality at the cost of lower quality metric scores. It only has effect when --rdoq-level is 1 or 2. High values can be beneficial in preserving high-frequency detail. Default: 0.0 (1.0 for presets slow, slower, veryslow)"
                },
                "open-gop":{
                    "valueType":"float",
                    "explanation":"Enable open GOP, allow I-slices to be non-IDR. \nDefault enabled"
                },
                "keyint":{
                    "valueType":"int",
                    "explanation":"Max intra period in frames. A special case of infinite-gop (single keyframe at the beginning of the stream) can be triggered with argument -1. Use 1 to force all-intra. When intra-refresh is enabled it specifies the interval between which refresh sweeps happen. \nDefault 250"
                },
                "min-keyint":{
                    "valueType":"int",
                    "explanation":"Range of values: >=0 (0: auto)\nMinimum GOP size. Scenecuts beyond this interval are coded as IDR and start a new keyframe, while scenecuts closer together are coded as I or P. For fixed keyframe interval, set value to be equal to keyint."
                },
                "scenecut":{
                    "valueType":"int",
                    "explanation":"How aggressively I-frames need to be inserted. The higher the threshold value, the more aggressive the I-frame placement. --scenecut 0 or --no-scenecut disables adaptive I frame placement. \nDefault 40"
                },
                "no-scenecut":{
                    "valueType":"boolean",
                    "explanation":"Disables adaptive I frame placement."
                },
                "scenecut-bias":{
                    "valueType":"float",
                    "explanation":"Range of values: 0 to 100.0\nThis value represents the percentage difference between the inter cost and intra cost of a frame used in scenecut detection. For example, a value of 5 indicates, if the inter cost of a frame is greater than or equal to 95 percent of the intra cost of the frame, then detect this frame as scenecut. Values between 5 and 15 are recommended. \nDefault 5."
                },
                "hist-scenecut":{
                    "valueType":"boolean",
                    "explanation":"Indicates that scenecuts need to be detected using luma edge and chroma histograms. --hist-scenecut enables scenecut detection using the histograms and disables the default scene cut algorithm. --no-hist-scenecut disables histogram based scenecut algorithm."
                },
                "hist-threshold":{
                    "valueType":"float",
                    "explanation":"Range of values: 0 to 1.0\nThis value represents the threshold for normalized SAD of edge histograms used in scenecut detection. This requires --hist-scenecut to be enabled. For example, a value of 0.2 indicates that a frame with normalized SAD value greater than 0.2 against the previous frame as scenecut. Increasing the threshold reduces the number of scenecuts detected. \nDefault 0.03."
                },
                "radl":{
                    "valueType":"float",
                    "explanation":"Range of values: Between 0 and –bframes\nNumber of RADL pictures allowed infront of IDR. Requires closed gop interval. If enabled for fixed keyframe interval, inserts RADL at every IDR. If enabled for closed gop interval, in case of --hist-scenecut inserts RADL at every hard scenecut whereas for the --scenecut, inserts RADL at every scenecut. Recommended value is 2-3. Default 0 (disabled)."
                },
                "ctu-info":{
                    "valueType":"float",
                    "explanation":"This value enables receiving CTU information asynchronously and determine reaction to the CTU information. Default 0. 1: force the partitions if CTU information is present. 2: functionality of (1) and reduce qp if CTU information has changed. 4: functionality of (1) and force Inter modes when CTU Information has changed, merge/skip otherwise. This option should be enabled only when planning to invoke the API function x265_encoder_ctu_info to copy ctu-info asynchronously. If enabled without calling the API function, the encoder will wait indefinitely."
                },
                "intra-refresh":{
                    "valueType":"boolean",
                    "explanation":"Enables Periodic Intra Refresh(PIR) instead of keyframe insertion. PIR can replace keyframes by inserting a column of intra blocks in non-keyframes, that move across the video from one side to the other and thereby refresh the image but over a period of multiple frames instead of a single keyframe."
                },
                "rc-lookahead":{
                    "valueType":"boolean",
                    "explanation":"Default 20. Range of values: Between the maximum consecutive bframe count (--bframes) and 250\nNumber of frames for slice-type decision lookahead (a key determining factor for encoder latency). The longer the lookahead buffer the more accurate scenecut decisions will be, and the more effective cutree will be at improving adaptive quant. Having a lookahead larger than the max keyframe interval is not helpful."
                },
                "gop-lookahead":{
                    "valueType":"boolean",
                    "explanation":"Default 0. Range of values: Between 0 and (–rc-lookahead - mini-GOP length)\nNumber of frames for GOP boundary decision lookahead. If a scenecut frame is found within this from the gop boundary set by –keyint, the GOP will be extended until such a point, otherwise the GOP will be terminated as set by –keyint. \nIt is recommended to have –gop-lookahaed less than –min-keyint as scenecuts beyond –min-keyint are already being coded as keyframes."
                },
                "lookahead-slices":{
                    "valueType":"int",
                    "explanation":"Use multiple worker threads to measure the estimated cost of each frame within the lookahead. The frame is divided into the specified number of slices, and one-thread is launched per slice. When --b-adapt is 2, most frame cost estimates will be performed in batch mode (many cost estimates at the same time) and lookahead-slices is ignored for batched estimates; it may still be used for single cost estimations. The higher this parameter, the less accurate the frame costs will be (since context is lost across slice boundaries) which will result in less accurate B-frame and scene-cut decisions. The effect on performance can be significant especially on systems with many threads.\nThe encoder may internally lower the number of slices or disable slicing to ensure each slice codes at least 10 16x16 rows of lowres blocks to minimize the impact on quality. For example, for 720p and 1080p videos, the number of slices is capped to 4 and 6, respectively. For resolutions lesser than 720p, slicing is auto-disabled.\nIf slices are used in lookahead, they are logged in the list of tools as lslices\nValues: 0 - disabled. 1 is the same as 0. Max 16. Default: 8 for ultrafast, superfast, faster, fast, medium\n4 for slow, slower disabled for veryslow, slower"
                },
                "lookahead-threads":{
                    "valueType":"int",
                    "explanation":"Use multiple worker threads dedicated to doing only lookahead instead of sharing the worker threads with frame Encoders. A dedicated lookahead threadpool is created with the specified number of worker threads. This can range from 0 upto half the hardware threads available for encoding. Using too many threads for lookahead can starve resources for frame Encoder and can harm performance. Default is 0 - disabled, Lookahead shares worker threads with other FrameEncoders .\nValues: 0 - disabled(default). Max - Half of available hardware threads."
                },
                "b-adapt":{
                    "valueType":"int",
                    "explanation":"Set the level of effort in determining B frame placement.\nWith b-adapt 0, the GOP structure is fixed based on the values of --keyint and --bframes.\nWith b-adapt 1 a light lookahead is used to choose B frame placement.\nWith b-adapt 2 (trellis) a viterbi B path selection is performed\nValues: 0:none; 1:fast; 2:full(trellis) default"
                },
                "bframes":{
                    "valueType":"int",
                    "explanation":"Range of values: 0 to 16\nMaximum number of consecutive b-frames. Use --bframes 0 to force all P/I low-latency encodes. \nDefault 4. \nThis parameter has a quadratic effect on the amount of memory allocated and the amount of work performed by the full trellis version of --b-adapt lookahead."
                },
                "bframe-bias":{
                    "valueType":"int",
                    "explanation":"Bias towards B frames in slicetype decision. The higher the bias the more likely x265 is to use B frames. \nCan be any value between -90 and 100 and is clipped to that range. Default 0"
                },
                "b-pyramid":{
                    "valueType":"int",
                    "explanation":"Use B-frames as references, when possible. Default enabled."
                },
                "force-flush":{
                    "valueType":"int",
                    "explanation":"Force the encoder to flush frames. Default is 0.\nValues: 0 - flush the encoder only when all the input pictures are over. \n1 - flush all the frames even when the input is not over. slicetype decision may change with this option.\n2 - flush the slicetype decided frames only."
                },
                "crf-max":{
                    "valueType":"int",
                    "explanation":"Range of values: 0 to 51.\nSpecify an upper limit to the rate factor which may be assigned to any given frame (ensuring a max QP). This is dangerous when CRF is used in combination with VBV as it may result in buffer underruns. \nDefault disabled"
                },
                "crf-min":{
                    "valueType":"int",
                    "explanation":"Specify a lower limit to the rate factor which may be assigned to any given frame (ensuring a min compression factor)."
                },
                "vbv-bufsize":{
                    "valueType":"int",
                    "explanation":"Specify the size of the VBV buffer (kbits). Enables VBV in ABR mode. In CRF mode, --vbv-maxrate must also be specified. Default 0 (vbv disabled)"
                },
                "vbv-maxrate":{
                    "valueType":"int",
                    "explanation":"Maximum local bitrate (kbits/sec). Will be used only if vbv-bufsize is also non-zero. Both vbv-bufsize and vbv-maxrate are required to enable VBV in CRF mode. \nDefault 0 (disabled)\nNote that when VBV is enabled (with a valid --vbv-bufsize), VBV emergency denoising is turned on. This will turn on aggressive denoising at the frame level when frame QP > QP_MAX_SPEC (51), drastically reducing bitrate and allowing ratecontrol to assign lower QPs for the following frames. The visual effect is blurring, but removes significant blocking/displacement artifacts."
                },
                "vbv-init":{
                    "valueType":"float",
                    "explanation":"Default 0.9\nRange of values: fractional: 0 - 1.0, or kbits: 2 .. bufsize\nInitial buffer occupancy. The portion of the decode buffer which must be full before the decoder will begin decoding. Determines absolute maximum frame size. May be specified as a fractional value between 0 and 1, or in kbits. In other words, these two option pairs are equivalent:\n--vbv-bufsize 1000 --vbv-init 900\n--vbv-bufsize 1000 --vbv-init 0.9"
                },
                "vbv-end":{
                    "valueType":"float",
                    "explanation":"Final buffer fullness. The portion of the decode buffer that must be full after all the specified frames have been inserted into the decode buffer. Specified as a fractional value between 0 and 1, or in kbits. \nDefault 0 (disabled)\nThis enables basic support for chunk-parallel encoding where each segment can specify the starting and ending state of the VBV buffer so that VBV compliance can be maintained when chunks are independently encoded and stitched together."
                },
                "vbv-end-fr-adj":{
                    "valueType":"float",
                    "explanation":"Frame from which qp has to be adjusted to achieve final decode buffer fullness. Specified as a fraction of the total frames. Fractions > 0 are supported only when the total number of frames is known. \nDefault 0."
                },
                "min-vbv-fullness":{
                    "valueType":"double",
                    "explanation":"Minimum VBV fullness percentage to be maintained. Specified as a fractional value ranging between 0 and 100. Default 50 i.e, Tries to keep the buffer at least 50% full at any point in time.\nDecreasing the minimum required fullness shall improve the compression efficiency, but is expected to affect VBV conformance. Experimental option."
                },
                "max-vbv-fullness":{
                    "valueType":"double",
                    "explanation":"Maximum VBV fullness percentage to be maintained. Specified as a fractional value ranging between 0 and 100. Default 80 i.e Tries to keep the buffer at max 80% full at any point in time.\nIncreasing the minimum required fullness shall improve the compression efficiency, but is expected to affect VBV conformance. \nExperimental option."
                },
                "lossless":{
                    "valueType":"boolean",
                    "explanation":"Enables true lossless coding by bypassing scaling, transform, quantization and in-loop filter processes. This is used for ultra-high bitrates with zero loss of quality. Reconstructed output pictures are bit-exact to the input pictures. Lossless encodes implicitly have no rate control, all rate control options are ignored. Slower presets will generally achieve better compression efficiency (and generate smaller bitstreams). \nDefault disabled."
                },
                "aq-mode":{
                    "valueType":"int",
                    "explanation":"Adaptive Quantization operating mode. Raise or lower per-block quantization based on complexity analysis of the source image. The more complex the block, the more quantization is used. These offsets the tendency of the encoder to spend too many bits on complex areas and not enough in flat areas.\n0: disabled\n1: AQ enabled\n2: AQ enabled with auto-variance (default)\n3: AQ enabled with auto-variance and bias to dark scenes. This is recommended for 8-bit encodes or low-bitrate 10-bit encodes, to prevent color banding/blocking.\n4: AQ enabled with auto-variance and edge information."
                }
                
            }
        }
    }
}